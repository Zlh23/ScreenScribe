# 按对比度与期望 L/C/H 反算前景色：前因后果与 ML 方案

本文档整理「背景 + 期望亮度/饱和度/色相/对比度 → 前景色」这一问题的来龙去脉，以及为何考虑用机器学习在独立项目中解决。之后可在别的文件夹里基于此文档实现模型与训练。

---

## 1. 问题来源与目标

### 1.1 需求

在 **zlh-web-theme** 中，除了「主色 → 固定 5 色相 + 整站 token」的用法外，希望有一个**独立工具**：

- **输入**  
  - 背景色（任意 CSS 颜色）  
  - 目标 APCA 对比度（绝对值，如 60）  
  - 期望亮度 L、期望饱和度 C、期望色相 H（OKLCH；在满足对比度的前提下尽量接近）

- **输出**  
  - 一个前景色（OKLCH 的 `{ l, c, h }`）  
  - 该前景在给定背景上的**实际 APCA 对比度**（用于展示/校验）

要求：**与 ColorTheme 无关**，纯函数；返回的是「计算出的颜色」格式（OKLCH），不做 rgb/hex 等输出格式转换。

### 1.2 为何不能固定 L、C、H

若同时**固定**亮度、饱和度、色相，则自由度只剩「是否满足目标对比度」：对灰阶（C=0）而言，一个 L 只对应一个对比度，往往**无解**。因此改为「期望」L/C/H，在满足对比度的前提下**尽可能接近**这些期望值。

---

## 2. 当前实现思路（本仓库 `colorForContrast`）

### 2.1 算法概要

- **第一步**：对网格上的每个 (C, H)，在 **L 方向**做一维搜索（约 28 步），找到使「当前前景与背景的 APCA 对比度」最接近目标对比度的 L，得到该 (C,H) 下的最优候选 `(L, C, H)` 及实际对比度。
- **第二步**：对所有候选打分  
  `score = contrastErr × 500 + (L - wantL)² + (C - wantC)² + hDist²`  
  其中 `hDist` 为与期望 H 的圆周角度差（归一化到 0–1）。
- **第三步**（当前方案）：用 **softmin 加权平均**，而非只取 score 最小的一格：  
  权重 `w_i = exp(-(score_i - minScore) / T)`，对 L、C 做加权平均，对 H 做**圆周加权平均**（sin/cos + atan2）。  
  最终 (L,C,H) 再经 `toGamut` 映射到色域，并重新算一次实际对比度返回。

这样做的目的：**输入（背景、期望 L/C/H、目标对比度）微调时，输出应连续、平滑变化**，避免在离散网格之间「跳色」。

### 2.2 依赖与接口

- 对比度：**APCA**（`apca-w3`）。
- 颜色空间：**OKLCH**，色域映射用 `culori`（clampGamut）等。
- 本仓库 API：`colorForContrast(options)`，选项含 `background, contrast, lightness, chroma, hue?`，返回 `{ l, c, h, contrast }`。

---

## 3. 曾尝试过的「平滑」方案与结论

### 3.1 用「上一帧结果」做锚点（已废弃，用户反馈：完全错误）

- **做法**：增加 `previousResult?: { l, c, h }`，在打分中加上与上一帧的偏差惩罚（如 `PREV_WEIGHT * (与上一帧的 L/C/H 距离)`），Demo 用 ref 保存上一帧并传入。
- **问题**：本质是「把上一帧的前景色强行拽过来」，和**当前背景**无关。背景变了，理应得到一个新的、与**新背景**匹配的前景；用上一帧锚定会得到错误的方向，因此被判定为**完全错误**，已移除。

### 3.2 当前方案：softmin 加权平均

- **做法**：不取 argmin(score)，而是按 `exp(-(score - minScore)/T)` 对全部候选做加权平均（L/C 线性平均，H 圆周平均）。
- **效果**：得分随输入连续变化时，加权平均后的 (L,C,H) 也连续变化，理论上能减轻「背景微调 h 时前景乱跳」。
- **局限**：仍基于离散 (C,H) 网格 + 离散 L 步进，本质是离散采样再平滑；若希望**严格连续、且可学习复杂关系**，用神经网络更合适。

---

## 4. 为何考虑用机器学习在独立项目里做

- **平滑性**：网络是连续映射，输入（背景、期望 L/C/H、目标对比度）微调时，输出自然连续，不会在格点间跳动。
- **速度**：推理一次前向即可，无需在 (L,C,H) 上做网格搜索或多次 APCA。
- **数据**：可用本仓库的 `colorForContrast`（或更精细的搜索）在大量 **(背景, 期望 L, 期望 C, 期望 H, 目标对比度)** 上生成**合成标注**，无需人工标注。
- **表达力**：可学习「背景与可行前景」的复杂关系，而不局限于当前手写打分与网格形状。

因此适合在**别的文件夹**新建一个 ML 项目，专门训练「背景 + 期望 → 前景」的模型；本仓库保留现有 `colorForContrast` 作为工具与数据生成/验证用。

---

## 5. ML 方案设想（供新项目实现）

### 5.1 输入 / 输出

- **输入**  
  - 背景色：建议用 OKLCH 或 RGB 的 3 维（或加 Fourier 特征）。  
  - 期望：`(wantL, wantC, wantH, wantContrast)`，每个可离散成 bin 做 embedding，或连续值过小 MLP 得到向量。
- **输出**  
  - 前景色：OKLCH 的 `(L, C, H)`；L/C 可 clamp 到 [0,1]、[0,0.4] 等，H 为 0–360（可回归后 mod 360 或圆周损失）。

### 5.2 结构设想（你提到的「矩阵乘」）

- **背景** → 网络（如 MLP 或小 CNN）→ 得到与背景相关的表示，例如矩阵 `W`（如 `d×k`）或向量。
- **期望** → 对 (wantL, wantC, wantH, wantContrast) 做 **embedding**（离散 bin embedding 或连续 MLP）→ 向量 `e`。
- **组合**：用背景得到的参数与 `e` 做**矩阵乘**（或双线性）：例如 `h = W @ e`，表示「在该背景下，这样一组期望应映射到怎样的前景表示」。
- **解码**：`h` → MLP → 输出 (L, C, H)，再做 clamp / 周期化。

这样「背景决定如何解释用户的期望」，不同背景会给出不同的线性（或仿射）映射，适合在独立项目中实现和调参。

### 5.3 训练数据与损失

- **数据**：在本仓库或能调用 `colorForContrast` 的环境里，随机或网格采样大量 **(background, wantL, wantC, wantH, wantContrast)**，调用现有实现得到**真值前景 (L, C, H)** 与**实际对比度**；可过滤掉对比度误差过大的样本。
- **损失**：  
  - L、C：MSE 或 L1。  
  - H：圆周损失，例如 `1 - cos((pred_h - true_h) * π/180)` 或类似，避免 0° 与 360° 断裂。  
  - 可选：加一项「预测前景与背景的 APCA 对比度」与目标对比度的误差（若在训练时能调用 APCA）。

### 5.4 与本仓库的关系

- 本仓库：保留并维护 `colorForContrast`（当前基于网格 + softmin），作为**数据生成器**和**对比/回退**实现。
- 新项目：只依赖「问题定义 + 输入输出格式 + 数据生成方式」，可在任意文件夹实现模型、训练与推理；部署时只需前向计算，无需依赖本仓库的搜索逻辑。

---

## 6. 小结

| 项目 | 说明 |
|------|------|
| **问题** | 背景 + 目标对比度 + 期望 L/C/H → 前景色（OKLCH）+ 实际对比度；要求平滑、可微、与 ColorTheme 解耦。 |
| **当前实现** | 网格 (C,H) + 每格对 L 一维搜索 → 候选集 → softmin 加权平均 → toGamut + 实际对比度。 |
| **废弃方案** | 用 previousResult 锚定上一帧：错误，已移除。 |
| **ML 方向** | 背景 → 网络 → 与「期望 L/C/H/对比度」的 embedding 做矩阵乘 → 解码 → 前景；用本仓库生成标注，在新项目里训练与部署。 |

把上述前因后果与 ML 设想写进本文档，便于在别的文件夹中复现问题定义并实现「背景 → 网络 → (期望 embedding) 矩阵乘 → 前景色」的完整流程。
